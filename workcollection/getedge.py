import os
import fitz  # PyMuPDF
import re
import csv
from collections import defaultdict

pdf_folder = r"D:\pythoncode\page4400edge\pdfs2500"
output_csv = 'author_citation_adjlist.csv'
fail_log = 'failed_files.txt'

# é»‘åå•å…³é”®è¯
blacklist = {
    "Engineering", "Mathematics", "Learning", "Deep Learning", "Gradient",
    "Computer", "Abstract", "Theory", "Discrete", "Modeling", "Classification",
    "Phishing", "Sickness", "Comfort", "On Doctrines", "Cartesian",
    "Information", "Semimodules", "Similarity", "Injection", "Improving",
    "Fibered", "Objects", "Evaluation", "Websites", "Attack", "Persona",
    "Tree", "Combining", "Security", "Privacy", "Technology", "Networks"
}


# === æå–å…¨æ–‡æ–‡æœ¬ ===
def extract_text_from_pdf(pdf_path):
    try:
        doc = fitz.open(pdf_path)
        text = ''
        for page in doc:
            text += page.get_text()
        return text
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {pdf_path}: {e}")
        return ''


# === ä½œè€…æå–ï¼šå‰20è¡Œï¼Œæ£€æµ‹é€—å·æˆ–andçš„è¡Œ ===
def extract_authors(text):
    lines = text.strip().split('\n')
    nonempty_lines = [line.strip() for line in lines if line.strip()]

    if len(nonempty_lines) < 2:
        return []

    candidate_lines = nonempty_lines[:20]

    for line in candidate_lines:
        if ('@' in line or 'university' in line.lower() or 'department' in line.lower()):
            continue
        if ',' not in line and ' and ' not in line:
            continue

        name_candidates = re.findall(r'\b[A-Z][a-z]+(?: [A-Z][a-z]+)+\b', line)
        filtered = []
        for name in name_candidates:
            if name in blacklist:
                continue
            if len(name.split()) >= 2:
                filtered.append(name)

        if 1 <= len(filtered) <= 8:
            return filtered

    return []


# === ä¼˜åŒ–ï¼šå‚è€ƒæ–‡çŒ®åŒºåŸŸæå–ï¼ˆæ¨¡ç³ŠåŒ¹é… + å1/3æ–‡æœ¬ï¼‰ ===
def extract_references_section(text):
    start = int(len(text) * 0.66)
    tail_text = text[start:]

    keywords = ['references', 'å‚è€ƒæ–‡çŒ®', 'bibliography', 'works cited', 'literature', 'å‚è€ƒ', 'æ–‡çŒ®']
    pattern = '|'.join(keywords)

    match = re.search(pattern, tail_text, re.IGNORECASE)
    if match:
        return tail_text[match.start():]

    return ''


# === ä»ç¼–å·åˆ°å¼•å·å‰æå–è¢«å¼•ç”¨ä½œè€…å ===
def extract_cited_authors(refs_text):
    # æå–ç¼–å·ååˆ°ç¬¬ä¸€ä¸ªè‹±æ–‡å¼•å· or å¥å·ä¹‹é—´çš„å†…å®¹
    pattern = re.findall(r'(?:\[\d+\]|\d+\.)\s*(.*?)(?=["â€œ\.])', refs_text)
    cleaned = []

    for raw in pattern:
        author_part = raw.strip().strip(',;:â€“â€”')  # å»æ‰æœ«å°¾æ ‡ç‚¹
        if 1 <= len(author_part.split()) <= 12:
            cleaned.append(author_part)

    return list(set(cleaned))

# === å†™é‚»æ¥å­—å…¸æ ¼å¼CSV ===
def write_adjacency_dict(edges, output_csv):
    adjacency_dict = defaultdict(lambda: defaultdict(int))
    for _, source_author, target_author in edges:
        adjacency_dict[source_author][target_author] += 1

    with open(output_csv, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['Nameï¼ˆå½“å‰ä½œè€…ï¼‰', 'Valueï¼ˆè¯¥ä½œè€…å¼•ç”¨è¿‡çš„ä½œè€…åŠå¼•ç”¨æ¬¡æ•°ï¼‰'])
        for author, neighbors in adjacency_dict.items():
            writer.writerow([author, dict(neighbors)])


# === ä¸»å‡½æ•° ===
def main():
    edges = []
    failed_files = []

    for filename in os.listdir(pdf_folder):
        if filename.lower().endswith('.pdf'):
            filepath = os.path.join(pdf_folder, filename)
            print(f"ğŸ“„ æ­£åœ¨å¤„ç†: {filename}")
            full_text = extract_text_from_pdf(filepath)

            source_authors = extract_authors(full_text)
            if not source_authors:
                print(f"âš ï¸ æœªæå–åˆ°ä½œè€…: {filename}")
                failed_files.append(f"{filename} - æœªè¯†åˆ«ä½œè€…")
                continue

            refs_text = extract_references_section(full_text)
            target_authors = extract_cited_authors(refs_text)
            if not target_authors:
                print(f"âš ï¸ æœªæå–åˆ°å‚è€ƒæ–‡çŒ®: {filename}")
                failed_files.append(f"{filename} - æœªè¯†åˆ«å‚è€ƒæ–‡çŒ®")
                continue

            for source_author in source_authors:
                for target_author in target_authors:
                    edges.append((filename, source_author, target_author))

    # å†™é‚»æ¥è¡¨
    write_adjacency_dict(edges, output_csv)

    # å†™å¤±è´¥æ—¥å¿—
    if failed_files:
        with open(fail_log, 'w', encoding='utf-8') as f:
            f.write("\n".join(failed_files))
        print(f"âš ï¸ æœ‰ {len(failed_files)} ä¸ªæ–‡ä»¶è¯†åˆ«å¤±è´¥ï¼Œå·²è®°å½•åˆ° {fail_log}")

    print(f"\nâœ… å¼•ç”¨é‚»æ¥è¡¨å·²è¾“å‡ºè‡³: {output_csv}")
    print(f"ğŸ“¦ å…±æ„å»ºå¼•ç”¨è¾¹: {len(edges)} æ¡")


if __name__ == '__main__':
    main()
